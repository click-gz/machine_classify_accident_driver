{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_excel(path=\"./data.xlsx\"):\n",
    "    data_xls = pd.io.excel.ExcelFile(path)\n",
    "    data = {}\n",
    "    print(data_xls.sheet_names)\n",
    "    for name in data_xls.sheet_names:\n",
    "        df = pd.read_excel(data_xls, sheet_name=name)\n",
    "        data[name] = df\n",
    "        # print(name, \" : df = \",df , type(df))\n",
    "        if df.empty:\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "\n",
    "data = read_excel()\n",
    "data\n",
    "pinformation = data[\"驾驶员基本信息\"]\n",
    "pwork = data[\"工作时长\"]\n",
    "service_violation = data[\"服务违章\"]\n",
    "safety_violation = data[\"安全违章\"]\n",
    "safety_accident = data[\"安全事故\"]\n",
    "# pinformation\n",
    "# 男 - 1 ； 女 - 0\n",
    "pinformation[\"性别\"].value_counts()\n",
    "pinformation.loc[pinformation[\"性别\"] == '男', '性别'] = 1\n",
    "pinformation.loc[pinformation[\"性别\"] == '女', '性别'] = 0\n",
    "pinformation\n",
    "pinformation[\"分公司\"].value_counts()\n",
    "pinformation = pinformation.drop(labels=\"分公司\", axis=1)\n",
    "pinformation\n",
    "pinformation[\"学历\"].value_counts()\n",
    "# 普高 0，中专 1， 初中 2， 大专 3， 高中（普高） 4， 本科 5， 技校 6， 职高 7 ，小学 8， nan 9\n",
    "pinformation.loc[pinformation[\"学历\"] == '普高', '学历'] = 0\n",
    "pinformation.loc[pinformation[\"学历\"] == '中专', '学历'] = 1\n",
    "pinformation.loc[pinformation[\"学历\"] == '初中', '学历'] = 2\n",
    "pinformation.loc[pinformation[\"学历\"] == '大专', '学历'] = 3\n",
    "pinformation.loc[pinformation[\"学历\"] == '高中（普高）', '学历'] = 4\n",
    "pinformation.loc[pinformation[\"学历\"] == '本科', '学历'] = 5\n",
    "pinformation.loc[pinformation[\"学历\"] == '技校', '学历'] = 6\n",
    "pinformation.loc[pinformation[\"学历\"] == '职高', '学历'] = 7\n",
    "pinformation.loc[pinformation[\"学历\"] == '小学', '学历'] = 8\n",
    "pinformation[\"学历\"] = pinformation[\"学历\"].fillna(9)\n",
    "pinformation\n",
    "pinformation['出生日期'] = pd.to_datetime(pinformation['出生日期'])\n",
    "import datetime as dt\n",
    "\n",
    "now_year = dt.datetime.today().year\n",
    "# pinformation['age'] = now_year - frame.birth.dt.year\n",
    "pinformation['出生日期'] = now_year - pinformation['出生日期'].dt.year\n",
    "\n",
    "pinformation['入职日期'] = pd.to_datetime(pinformation['入职日期'])\n",
    "now_year = dt.datetime.today().year\n",
    "# pinformation['age'] = now_year - frame.birth.dt.year\n",
    "pinformation['入职日期'] = now_year - pinformation['入职日期'].dt.year\n",
    "\n",
    "pinformation\n",
    "# pinformation = pinformation.drop(labels=[\"事故\", \"安全违章\", \"服务违章\"], axis=1)\n",
    "\n",
    "safety_accident.columns = safety_accident.columns.str.replace('事故日期', '开班日期')\n",
    "\n",
    "safety_accident['开班日期'] = pd.to_datetime(safety_accident['开班日期'], format='%Y-%M-%d').dt.date.astype(object)\n",
    "safety_accident\n",
    "pwork['开班日期'] = pd.to_datetime(pwork['开班日期'], format='%Y-%M-%d').dt.date.astype(object)\n",
    "res = pd.merge(pwork, safety_accident, how='right', on=['员工编号', '开班日期'])\n",
    "res\n",
    "# print(safety_accident)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_1 = res['工作时长（小时）']\n",
    "y_2 = res['驾车时长（小时）']\n",
    "y_3 = res['运营时长（小时）']\n",
    "x = [i for i in range(len(y_1))]\n",
    "plt.plot(x, y_1)\n",
    "plt.plot(x, y_2)\n",
    "plt.plot(x, y_3)\n",
    "plt.show()\n",
    "\n",
    "print(res)\n",
    "import seaborn as sns\n",
    "\n",
    "hres = res[[\"工作时长（小时）\", \"驾车时长（小时）\", \"运营时长（小时）\"]]\n",
    "plot = sns.heatmap(res)\n",
    "plt.show()\n",
    "hh = pd.merge(pwork, safety_accident, how='left', on=['员工编号'])\n",
    "hh.insert(loc=len(hh.columns.array), column=\"事故\", value=1)\n",
    "hh.loc[hh['事故原因'].isna(), \"事故\"] = 0\n",
    "print(hh)\n",
    "import seaborn as sns\n",
    "\n",
    "hres = hh[[\"工作时长（小时）\", \"驾车时长（小时）\", \"运营时长（小时）\", \"事故\"]]\n",
    "\n",
    "plt.subplots(figsize=(20, 15))\n",
    "ax = plt.axes()\n",
    "ax.set_title(\"Correlation Heatmap\")\n",
    "corr = hres.corr()\n",
    "sns.heatmap(corr,\n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "plt.show()\n",
    "\n",
    "oth_res = pd.merge(pwork, safety_accident, how='left', on=['员工编号'])\n",
    "print(oth_res)\n",
    "oth_y_1 = oth_res[oth_res['开班日期_y'].isna()]['工作时长（小时）']\n",
    "oth_y_2 = oth_res[oth_res['开班日期_y'].isna()]['驾车时长（小时）']\n",
    "oth_y_3 = oth_res[oth_res['开班日期_y'].isna()]['运营时长（小时）']\n",
    "oth_x = [i for i in range(len(oth_y_1))]\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.scatter(x, y_1)\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.scatter(oth_x, oth_y_1)\n",
    "plt.show()\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.scatter(x, y_2)\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.scatter(oth_x, oth_y_2)\n",
    "plt.show()\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.scatter(x, y_3)\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.scatter(oth_x, oth_y_3)\n",
    "plt.show()\n",
    "print(service_violation.groupby(service_violation['服务违章项目']).value_counts())\n",
    "service_res = pd.merge(service_violation, safety_accident, how='left', on=['员工编号'])\n",
    "print(service_res)\n",
    "no_num = len(service_res[oth_res['开班日期_y'].isna()])\n",
    "ys_num = len(service_res['服务违章项目']) - no_num\n",
    "plt.bar([0, 1], [no_num, ys_num], width=0.5)\n",
    "plt.show()\n",
    "plt.pie([float(no_num) / float(no_num + ys_num), float(ys_num) / float(no_num + ys_num)])\n",
    "plt.show()\n",
    "# pinformation\n",
    "# pinformation = pinformation.drop(labels=[ \"服务违章\"], axis=1)\n",
    "pinformation.insert(loc=6, column=\"服务违章\", value=0)\n",
    "\n",
    "pinformation.loc[pinformation[\"员工编号\"].isin(service_violation[\"员工编号\"]), \"服务违章\"] = 1\n",
    "pinformation\n",
    "safety_res = pd.merge(safety_violation, safety_accident, how='left', on=['员工编号'])\n",
    "print(safety_res)\n",
    "sno_num = len(safety_res[safety_res['开班日期'].isna()])\n",
    "sys_num = len(safety_res['安全违章项目']) - sno_num\n",
    "plt.bar([0, 1], [sno_num, sys_num], width=0.5)\n",
    "plt.show()\n",
    "plt.pie([float(sno_num) / float(sno_num + sys_num), float(sys_num) / float(sno_num + sys_num)])\n",
    "plt.show()\n",
    "\n",
    "pinformation.insert(loc=7, column=\"安全违章\", value=0)\n",
    "pinformation\n",
    "pinformation.loc[pinformation[\"员工编号\"].isin(safety_violation[\"员工编号\"]), \"安全违章\"] = 1\n",
    "print(pinformation[\"安全违章\"].value_counts())\n",
    "pinformation.insert(loc=8, column=\"事故\", value=0)\n",
    "pinformation\n",
    "pinformation.loc[pinformation[\"员工编号\"].isin(safety_accident[\"员工编号\"]), \"事故\"] = 1\n",
    "pinformation\n",
    "pinformation = pinformation.drop(labels=[\"初领证日期\"], axis=1)\n",
    "pinformation = pinformation.drop(labels=[\"员工编号\"], axis=1)\n",
    "# pinformation = pinformation.drop(labels=[\"入职日期\"], axis=1)\n",
    "pinformation\n",
    "print(pinformation['事故'].value_counts())\n",
    "pinformation.to_csv(\"./data1.csv\", index=False)\n",
    "print(pinformation[pinformation['安全违章'] == 1]['事故'].value_counts())\n",
    "data_list = pinformation.values.tolist()\n",
    "print(data_list)\n",
    "label_list = []\n",
    "for i in range(len(data_list)):\n",
    "    label_list.append([data_list[i][-1]])\n",
    "    data_list[i] = data_list[i][:-1]\n",
    "print(data_list)\n",
    "print(label_list)\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_data = torch.ones(100,2)\n",
    "x0 = torch.normal(2*n_data,1)\n",
    "y0 = torch.zeros(100)\n",
    "# print(x0)\n",
    "x1 = torch.normal(-2*n_data,1)\n",
    "y1 = torch.ones(100)\n",
    "\n",
    "\n",
    "x = torch.cat((x0,x1),0).type(torch.FloatTensor)\n",
    "y = torch.cat((y0,y1)).type(torch.LongTensor)\n",
    "# print(y)\n",
    "x,y = Variable(x),Variable(y)\n",
    "\n",
    "# plt.scatter(x[:,0],x[:,1],c=y.data.numpy(), s=100, lw=0, cmap='RdYlGn')\n",
    "# plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=y.data.numpy(), s=100, lw=0, cmap='RdYlGn')\n",
    "# plt.show()\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,n_input,n_hidden,n_output):\n",
    "        super(Net,self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(n_input,n_hidden)\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden,n_hidden)\n",
    "        self.predict = torch.nn.Linear(n_hidden,n_output)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.hidden1(input)\n",
    "        out = F.sigmoid(out)\n",
    "        out = self.hidden2(out)\n",
    "        out = F.sigmoid(out)\n",
    "        out = self.predict(out)\n",
    "        # out = F.softmax(out)\n",
    "        return out\n",
    "\n",
    "net = Net(6,24,2)\n",
    "print(net)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=0.02)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "plt.ion()\n",
    "plt.show()\n",
    "y = []\n",
    "for i in range(len(label_list)):\n",
    "    y.append(label_list[i][0])\n",
    "print(torch.tensor(y).shape)\n",
    "p1 = []\n",
    "p2 = []\n",
    "p3 = []\n",
    "p4 = []\n",
    "pp = None\n",
    "for t in range(200):\n",
    "    prediction = net(torch.tensor(data_list).type(torch.FloatTensor))\n",
    "    # p11, p22, p33, p44 = num_get(F.softmax(prediction).detach().numpy() , y)\n",
    "    # p1.append(p11)\n",
    "    # p2.append(p22)\n",
    "    # p3.append(p33)\n",
    "    # p4.append(p44)\n",
    "    # print(classification_report(prediction.detach().numpy(), y))\n",
    "    # print(prediction)\n",
    "    pp = prediction\n",
    "    print(F.softmax(prediction))\n",
    "    loss = loss_func(prediction,torch.tensor(y))\n",
    "    p1.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(t, \"  loss: \", loss.item())\n",
    "\n",
    "    # if t%2==0:\n",
    "    #     plt.cla()\n",
    "    #     # 过了一道 softmax 的激励函数后的最大概率才是预测值\n",
    "    #     # print(F.softmax(prediction))\n",
    "    #     prediction = torch.max(F.softmax(prediction),1)[1]\n",
    "    #     pred_y = prediction.data.numpy().squeeze()\n",
    "    #     target_y = torch.tensor(y).data.numpy()\n",
    "    #     plt.scatter(torch.tensor(data_list).data.numpy()[:, 0], torch.tensor(data_list).data.numpy()[:, 1], c=pred_y, s=100, lw=0, cmap='RdYlGn')\n",
    "    #     accuracy = sum(pred_y == target_y) / 200.  # 预测中有多少和真实值一样\n",
    "    #     plt.text(1.5, -4, 'Accuracy=%.2f' % accuracy, fontdict={'size': 20, 'color': 'red'})\n",
    "    #     plt.pause(0.1)\n",
    "\n",
    "plt.ioff()  # 停止画图\n",
    "plt.show()\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# plt.plot([i for i in range(len(p1))], p1)\n",
    "# plt.show()\n",
    "res_pre = []\n",
    "p = []\n",
    "for i in range(len(y)):\n",
    "    # print(test[i][-1], y_predict[i])\n",
    "    pp = pp.detach().numpy()\n",
    "    for j in range(2):\n",
    "        if pp[i][j] < 0:\n",
    "            pp[i][j]=0\n",
    "    pp = torch.tensor(pp)\n",
    "    res_pre.append(F.softmax(pp).detach().numpy()[i][int(y[i])])\n",
    "\n",
    "    print(pp[i], y[i], res_pre[i])\n",
    "Precision,Recall,throds = precision_recall_curve(y, res_pre)\n",
    "FPR,TPR,_ = roc_curve(y, res_pre)\n",
    "# print(y_predict.shape, test[:, -1].shape, Precision,Recall, throds)\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Preccision\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "plt.plot(Precision, Recall)\n",
    "plt.show()\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.plot(FPR, TPR)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
