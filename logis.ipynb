{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_excel(path=\"./data.xlsx\"):\n",
    "    data_xls = pd.io.excel.ExcelFile(path)\n",
    "    data={}\n",
    "    print(data_xls.sheet_names)\n",
    "    for name in data_xls.sheet_names:\n",
    "        df=pd.read_excel(data_xls,sheet_name=name)\n",
    "        data[name]=df\n",
    "        # print(name, \" : df = \",df , type(df))\n",
    "        if df.empty:\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "data = read_excel()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pinformation = data[\"驾驶员基本信息\"]\n",
    "pwork = data[\"工作时长\"]\n",
    "service_violation = data[\"服务违章\"]\n",
    "safety_violation = data[\"安全违章\"]\n",
    "safety_accident = data[\"安全事故\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pinformation\n",
    "# 男 - 1 ； 女 - 0\n",
    "pinformation[\"性别\"].value_counts()\n",
    "pinformation.loc[pinformation[\"性别\"]=='男' , '性别']=1\n",
    "pinformation.loc[pinformation[\"性别\"]=='女' , '性别']=0\n",
    "pinformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pinformation[\"分公司\"].value_counts()\n",
    "pinformation = pinformation.drop(labels=\"分公司\", axis=1)\n",
    "pinformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pinformation[\"学历\"].value_counts()\n",
    "# 普高 0，中专 1， 初中 2， 大专 3， 高中（普高） 4， 本科 5， 技校 6， 职高 7 ，小学 8， nan 9\n",
    "pinformation.loc[pinformation[\"学历\"]=='普高' , '学历']=0\n",
    "pinformation.loc[pinformation[\"学历\"]=='中专' , '学历']=1\n",
    "pinformation.loc[pinformation[\"学历\"]=='初中' , '学历']=2\n",
    "pinformation.loc[pinformation[\"学历\"]=='大专' , '学历']=3\n",
    "pinformation.loc[pinformation[\"学历\"]=='高中（普高）' , '学历']=4\n",
    "pinformation.loc[pinformation[\"学历\"]=='本科' , '学历']=5\n",
    "pinformation.loc[pinformation[\"学历\"]=='技校' , '学历']=6\n",
    "pinformation.loc[pinformation[\"学历\"]=='职高' , '学历']=7\n",
    "pinformation.loc[pinformation[\"学历\"]=='小学' , '学历']=8\n",
    "pinformation[\"学历\"] = pinformation[\"学历\"].fillna(9)\n",
    "pinformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pinformation['出生日期'] = pd.to_datetime(pinformation['出生日期'])\n",
    "import datetime as dt\n",
    "now_year = dt.datetime.today().year\n",
    "# pinformation['age'] = now_year - frame.birth.dt.year\n",
    "pinformation['出生日期'] = now_year - pinformation['出生日期'].dt.year\n",
    "\n",
    "pinformation['入职日期'] = pd.to_datetime(pinformation['入职日期'])\n",
    "now_year = dt.datetime.today().year\n",
    "# pinformation['age'] = now_year - frame.birth.dt.year\n",
    "pinformation['入职日期'] = now_year - pinformation['入职日期'].dt.year\n",
    "\n",
    "pinformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pinformation = pinformation.drop(labels=[\"事故\", \"安全违章\", \"服务违章\"], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "safety_accident.columns = safety_accident.columns.str.replace('事故日期', '开班日期')\n",
    "\n",
    "safety_accident['开班日期'] = pd.to_datetime(safety_accident['开班日期'],format='%Y-%M-%d').dt.date.astype(object)\n",
    "safety_accident\n",
    "pwork['开班日期'] = pd.to_datetime(pwork['开班日期'],format='%Y-%M-%d').dt.date.astype(object)\n",
    "res = pd.merge(pwork, safety_accident, how='right', on=['员工编号', '开班日期'])\n",
    "res\n",
    "# print(safety_accident)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_1 = res['工作时长（小时）']\n",
    "y_2 = res['驾车时长（小时）']\n",
    "y_3 = res['运营时长（小时）']\n",
    "x = [i for i in range(len(y_1))]\n",
    "plt.plot(x, y_1)\n",
    "plt.plot(x, y_2)\n",
    "plt.plot(x, y_3)\n",
    "plt.show()\n",
    "\n",
    "print(res)\n",
    "import seaborn as sns\n",
    "hres = res[[\"工作时长（小时）\", \"驾车时长（小时）\", \"运营时长（小时）\"]]\n",
    "plot=sns.heatmap(res)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hh = pd.merge(pwork, safety_accident, how='left', on=['员工编号'])\n",
    "hh.insert(loc=len(hh.columns.array), column=\"事故\", value = 1)\n",
    "hh.loc[hh['事故原因'].isna(), \"事故\"]  = 0\n",
    "print(hh)\n",
    "import seaborn as sns\n",
    "hres = hh[[\"工作时长（小时）\", \"驾车时长（小时）\", \"运营时长（小时）\", \"事故\"]]\n",
    "\n",
    "plt.subplots(figsize=(20,15))\n",
    "ax = plt.axes()\n",
    "ax.set_title(\"Correlation Heatmap\")\n",
    "corr = hres.corr()\n",
    "sns.heatmap(corr,\n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oth_res = pd.merge(pwork, safety_accident, how='left', on=['员工编号'])\n",
    "print(oth_res)\n",
    "oth_y_1 = oth_res[oth_res['开班日期_y'].isna()]['工作时长（小时）']\n",
    "oth_y_2 = oth_res[oth_res['开班日期_y'].isna()]['驾车时长（小时）']\n",
    "oth_y_3 = oth_res[oth_res['开班日期_y'].isna()]['运营时长（小时）']\n",
    "oth_x = [i for i in range(len(oth_y_1))]\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.scatter(x, y_1)\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.scatter(oth_x, oth_y_1)\n",
    "plt.show()\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.scatter(x, y_2)\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.scatter(oth_x, oth_y_2)\n",
    "plt.show()\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.scatter(x, y_3)\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.scatter(oth_x, oth_y_3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(service_violation.groupby(service_violation['服务违章项目']).value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "service_res = pd.merge(service_violation, safety_accident, how='left', on=['员工编号'])\n",
    "print(service_res)\n",
    "no_num = len(service_res[oth_res['开班日期_y'].isna()])\n",
    "ys_num = len(service_res['服务违章项目']) - no_num\n",
    "plt.bar([0, 1], [no_num, ys_num],  width=0.5)\n",
    "plt.show()\n",
    "plt.pie([float(no_num)/float(no_num + ys_num), float(ys_num)/float(no_num + ys_num)])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pinformation\n",
    "# pinformation = pinformation.drop(labels=[ \"服务违章\"], axis=1)\n",
    "pinformation.insert(loc=6, column=\"服务违章\", value = 0)\n",
    "\n",
    "pinformation.loc[pinformation[\"员工编号\"].isin(service_violation[\"员工编号\"]), \"服务违章\"] = 1\n",
    "pinformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "safety_res = pd.merge(safety_violation, safety_accident, how='left', on=['员工编号'])\n",
    "print(safety_res)\n",
    "sno_num = len(safety_res[safety_res['开班日期'].isna()])\n",
    "sys_num = len(safety_res['安全违章项目']) - sno_num\n",
    "plt.bar([0, 1], [sno_num, sys_num],  width=0.5)\n",
    "plt.show()\n",
    "plt.pie([float(sno_num)/float(sno_num + sys_num), float(sys_num)/float(sno_num + sys_num)])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "pinformation.insert(loc=7, column=\"安全违章\", value = 0)\n",
    "pinformation\n",
    "pinformation.loc[pinformation[\"员工编号\"].isin(safety_violation[\"员工编号\"]), \"安全违章\"] = 1\n",
    "print(pinformation[\"安全违章\"].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pinformation.insert(loc=8, column=\"事故\", value = 0)\n",
    "pinformation\n",
    "pinformation.loc[pinformation[\"员工编号\"].isin(safety_accident[\"员工编号\"]), \"事故\"] = 1\n",
    "pinformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pinformation = pinformation.drop(labels=[\"初领证日期\"], axis=1)\n",
    "pinformation = pinformation.drop(labels=[\"员工编号\"], axis=1)\n",
    "# pinformation = pinformation.drop(labels=[\"入职日期\"], axis=1)\n",
    "pinformation\n",
    "print(pinformation['事故'].value_counts())\n",
    "pinformation.to_csv(\"./data1.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(pinformation[pinformation['安全违章']==1]['事故'].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_list = pinformation.values.tolist()\n",
    "print(data_list)\n",
    "label_list = []\n",
    "for i in range(len(data_list)):\n",
    "    label_list.append([data_list[i][-1]])\n",
    "    data_list[i] = data_list[i][:-1]\n",
    "print(data_list)\n",
    "print(label_list)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    \"\"\"\n",
    "    获取数据集\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    iris = load_iris()\n",
    "\n",
    "    return iris.data, iris.target\n",
    "\n",
    "\n",
    "def split_data(data, target):\n",
    "    \"\"\"\n",
    "    划分数据集\n",
    "    :param data:\n",
    "    :param target:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    target = np.array(target)\n",
    "    target = np.reshape(target, (target.shape[0], 1))\n",
    "\n",
    "    # 正则化数据，防止数据大小本身对结果造成影响\n",
    "    sd = StandardScaler()\n",
    "    data = sd.fit_transform(data)\n",
    "\n",
    "    # 拼接特征值与类别\n",
    "    dataset = np.hstack((data, target))\n",
    "    n = dataset.shape[0]\n",
    "\n",
    "    # 打乱数据\n",
    "    np.random.shuffle(dataset)\n",
    "\n",
    "    # 划分数据集，返回训练集与测试集\n",
    "    train = dataset[:int(0.75 * n), :]\n",
    "    test = dataset[int(0.75 * n):, :]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    sigmoid函数\n",
    "    :param z:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def draw_sigmoid():\n",
    "    \"\"\"\n",
    "    画出sigmoid函数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    x_data = np.arange(-10, 10, 0.1)\n",
    "    ax.plot(x_data, sigmoid(x_data))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calCost(dataset, theta):\n",
    "    \"\"\"\n",
    "    计算代价函数\n",
    "    :param dataset:\n",
    "    :param theta:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = dataset[:, :-1]\n",
    "    y = dataset[:, -1:]\n",
    "    z = x @ theta.T\n",
    "    # 训练数据个数,或者用m = y.shape[1]\n",
    "    m = y.size\n",
    "    para1 = np.multiply(-y, np.log(sigmoid(z)))\n",
    "    para2 = np.multiply((1 - y), np.log(1 - sigmoid(z)))\n",
    "    # 代价函数Y\n",
    "    J = 1 / m * np.sum(para1 - para2)\n",
    "    return J\n",
    "\n",
    "\n",
    "def gradient(dataset, theta, iters, alpha):\n",
    "    \"\"\"\n",
    "    梯度下降\n",
    "    :param dataset:\n",
    "    :param theta:\n",
    "    :param iters:\n",
    "    :param alpha:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 存放每次梯度下降后的损失值\n",
    "    x = dataset[:, :-1]\n",
    "    y = dataset[:, -1:]\n",
    "    for i in range(iters):\n",
    "        print(\"T: \", theta.T)\n",
    "        h_x = sigmoid(x @ theta.T)\n",
    "\n",
    "        theta = theta - alpha / len(x) * (h_x - y).T @ x\n",
    "    return theta\n",
    "\n",
    "\n",
    "def get_per_classify_data(data, i):\n",
    "    \"\"\"\n",
    "    返回第i类的数据\n",
    "    :param data:数据集\n",
    "    :param i:类别\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return data[data[:, -1] == i]\n",
    "\n",
    "\n",
    "def get_final_theta(data, i, theta, iters, alpha):\n",
    "    \"\"\"\n",
    "    获取梯度下降后的theta值\n",
    "    :param data:\n",
    "    :param i:\n",
    "    :param theta:\n",
    "    :param iters:\n",
    "    :param alpha:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataset = get_per_classify_data(data, i)\n",
    "    return gradient(dataset, theta, iters, alpha)\n",
    "\n",
    "\n",
    "def predict(dataset, theta_list):\n",
    "    \"\"\"\n",
    "    预测结果\n",
    "    :param dataset:\n",
    "    :param theta_list:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = dataset[:, :-1]\n",
    "    per_theta_list = [i[0] for i in theta_list]\n",
    "    per_theta_list = np.array(per_theta_list)\n",
    "\n",
    "    per_prob = sigmoid(np.dot(x, per_theta_list.T))\n",
    "\n",
    "    # 返回每行最大值所在的索引，即概率最大的类别\n",
    "    # print(np.max(per_prob, axis=1))\n",
    "    # return np.argmax(per_prob, axis=1)\n",
    "    return per_prob\n",
    "\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plt.rcParams['font.sans-serif'] = 'SimHei'  # 黑体\n",
    "    plt.rcParams['axes.unicode_minus'] = False  # 显示负号\n",
    "\n",
    "    data, target = get_data()\n",
    "\n",
    "    target_list = []\n",
    "    for i in label_list:\n",
    "        target_list.append(i[0])\n",
    "\n",
    "    # print(data.shape, target.shape, np.array(data_list).shape, np.array(target_list).shape)\n",
    "    # print(target_list)\n",
    "    train, test = split_data(np.array(data_list), np.array(target_list))\n",
    "    # draw_sigmoid()\n",
    "\n",
    "    iters = 1000 # 迭代次数\n",
    "    alpha = 0.5 # 学习率\n",
    "    theta_list = []\n",
    "    for i in range(np.array(data_list).shape[1]):\n",
    "        theta = np.zeros((1, np.array(data_list).shape[1]))\n",
    "        theta_list.append(theta)\n",
    "\n",
    "    final_theta_list = []\n",
    "    target_list1 = list(set(np.array(target_list)))\n",
    "\n",
    "    for i in target_list1:\n",
    "        theta_i = get_final_theta(train, i, theta_list[target_list1.index(i)], iters, alpha)\n",
    "        final_theta_list.append(theta_i)\n",
    "\n",
    "\n",
    "    y_predict = predict(test, final_theta_list)\n",
    "    res_pre = []\n",
    "    # print(y_predict.shape,test.shape)\n",
    "    for i in range(len(test)):\n",
    "        # print(test[i][-1], y_predict[i])\n",
    "        res_pre.append(y_predict[i][int(test[i][-1])])\n",
    "        # print(test[i][-1], y_predict[i], res_pre[i])\n",
    "    Precision,Recall,throds = precision_recall_curve(test[:, -1], res_pre)\n",
    "    FPR,TPR,_ = roc_curve(test[:, -1], res_pre)\n",
    "    # print(y_predict.shape, test[:, -1].shape, Precision,Recall, throds)\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Preccision\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "\n",
    "    plt.plot(Precision, Recall)\n",
    "    plt.show()\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.plot(FPR, TPR)\n",
    "    plt.show()\n",
    "    # 查看预测准确度\n",
    "    # print(classification_report(y_predict, test[:, -1]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
